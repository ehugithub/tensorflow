{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67697de1",
   "metadata": {},
   "source": [
    "### Data set: sizes of various flower parts\n",
    "- given certain parameters, will attempt to predict what flower it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "139502ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 21:22:47.043032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-21 21:22:47.043078: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from six.moves import urllib\n",
    "import tensorflow.compat.v2.feature_column as fc\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ed7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23d91466",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMNS, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMNS, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50954f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2f062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # convert inputs into dataset\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "    \n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "    \n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "860b7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature columns\n",
    "feature_columns = []\n",
    "for key in train.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1400b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d384af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp9r7fbg7f\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp9r7fbg7f', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 21:23:02.350556: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-21 21:23:02.350621: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n",
      "2022-07-21 21:23:02.351071: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "# we'll use a classification model, of which there are hundreds of different types\n",
    "# DNN (deep neural network) classifier\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns = feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes\n",
    "    hidden_units = [30, 10],\n",
    "    # 3 different classes to choose from\n",
    "    n_classes = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09be99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/erichu/.local/lib/python3.10/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/erichu/.local/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adagrad.py:86: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-21 21:23:06.054042: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-07-21 21:23:06.065303: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT64\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'dnn/zero_fraction/cond/output/_18'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp9r7fbg7f/model.ckpt.\n",
      "INFO:tensorflow:/tmp/tmp9r7fbg7f/model.ckpt-0.meta\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:/tmp/tmp9r7fbg7f/model.ckpt-0.index\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:/tmp/tmp9r7fbg7f/model.ckpt-0.data-00000-of-00001\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 2.3186398, step = 0\n",
      "INFO:tensorflow:global_step/sec: 182.19\n",
      "INFO:tensorflow:loss = 1.387519, step = 100 (0.552 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.937\n",
      "INFO:tensorflow:loss = 1.1652172, step = 200 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.425\n",
      "INFO:tensorflow:loss = 1.0287033, step = 300 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.342\n",
      "INFO:tensorflow:loss = 0.9447596, step = 400 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.224\n",
      "INFO:tensorflow:loss = 0.90734845, step = 500 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.795\n",
      "INFO:tensorflow:loss = 0.86240256, step = 600 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.584\n",
      "INFO:tensorflow:loss = 0.8231132, step = 700 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.78\n",
      "INFO:tensorflow:loss = 0.8045459, step = 800 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.205\n",
      "INFO:tensorflow:loss = 0.78888035, step = 900 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.032\n",
      "INFO:tensorflow:loss = 0.7717068, step = 1000 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.81\n",
      "INFO:tensorflow:loss = 0.7411446, step = 1100 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 526.645\n",
      "INFO:tensorflow:loss = 0.73446333, step = 1200 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.858\n",
      "INFO:tensorflow:loss = 0.7293679, step = 1300 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 458.099\n",
      "INFO:tensorflow:loss = 0.6985014, step = 1400 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.651\n",
      "INFO:tensorflow:loss = 0.6828712, step = 1500 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.041\n",
      "INFO:tensorflow:loss = 0.6663708, step = 1600 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.137\n",
      "INFO:tensorflow:loss = 0.65505254, step = 1700 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.822\n",
      "INFO:tensorflow:loss = 0.6514446, step = 1800 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.226\n",
      "INFO:tensorflow:loss = 0.63458204, step = 1900 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.46\n",
      "INFO:tensorflow:loss = 0.62822974, step = 2000 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.04\n",
      "INFO:tensorflow:loss = 0.6179229, step = 2100 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 472.769\n",
      "INFO:tensorflow:loss = 0.6257838, step = 2200 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.613\n",
      "INFO:tensorflow:loss = 0.6042506, step = 2300 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.83\n",
      "INFO:tensorflow:loss = 0.59474385, step = 2400 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.99\n",
      "INFO:tensorflow:loss = 0.5898633, step = 2500 (0.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.938\n",
      "INFO:tensorflow:loss = 0.589663, step = 2600 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 542.763\n",
      "INFO:tensorflow:loss = 0.5801318, step = 2700 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 551.016\n",
      "INFO:tensorflow:loss = 0.5719188, step = 2800 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.755\n",
      "INFO:tensorflow:loss = 0.56028235, step = 2900 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.077\n",
      "INFO:tensorflow:loss = 0.5611913, step = 3000 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 497.38\n",
      "INFO:tensorflow:loss = 0.5474242, step = 3100 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.938\n",
      "INFO:tensorflow:loss = 0.53801066, step = 3200 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.655\n",
      "INFO:tensorflow:loss = 0.5453163, step = 3300 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.104\n",
      "INFO:tensorflow:loss = 0.54583514, step = 3400 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 560.406\n",
      "INFO:tensorflow:loss = 0.51970863, step = 3500 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 570.307\n",
      "INFO:tensorflow:loss = 0.5260101, step = 3600 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.811\n",
      "INFO:tensorflow:loss = 0.52316725, step = 3700 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 565.308\n",
      "INFO:tensorflow:loss = 0.52224153, step = 3800 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.702\n",
      "INFO:tensorflow:loss = 0.51806325, step = 3900 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.679\n",
      "INFO:tensorflow:loss = 0.5127421, step = 4000 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 522.558\n",
      "INFO:tensorflow:loss = 0.51150894, step = 4100 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.864\n",
      "INFO:tensorflow:loss = 0.5113178, step = 4200 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.813\n",
      "INFO:tensorflow:loss = 0.49753022, step = 4300 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 549.223\n",
      "INFO:tensorflow:loss = 0.49423903, step = 4400 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.626\n",
      "INFO:tensorflow:loss = 0.4953181, step = 4500 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.723\n",
      "INFO:tensorflow:loss = 0.48975557, step = 4600 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.846\n",
      "INFO:tensorflow:loss = 0.49552056, step = 4700 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.781\n",
      "INFO:tensorflow:loss = 0.47658288, step = 4800 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.547\n",
      "INFO:tensorflow:loss = 0.49568084, step = 4900 (0.511 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tmp9r7fbg7f/model.ckpt.\n",
      "INFO:tensorflow:/tmp/tmp9r7fbg7f/model.ckpt-5000.meta\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:/tmp/tmp9r7fbg7f/model.ckpt-5000.index\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:/tmp/tmp9r7fbg7f/model.ckpt-5000.data-00000-of-00001\n",
      "INFO:tensorflow:100\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.4699846.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x7f0aa8710280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model\n",
    "classifier.train(\n",
    "    input_fn = lambda: input_fn(train, train_y, training=True),\n",
    "    steps = 5000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34fc187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-21T21:23:18\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9r7fbg7f/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.52650s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-21-21:23:19\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.89166665, average_loss = 0.4745093, global_step = 5000, loss = 0.4745093\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tmp9r7fbg7f/model.ckpt-5000\n",
      "\n",
      "Test set accuracy: 0.892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(input_fn = lambda: input_fn(test, test_y, training=False))\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82302611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric values as prompted:\n",
      "SepalLength: 5.1\n",
      "SepalWidth: 3.3\n",
      "PetalLength: 1.7\n",
      "PetalWidth: 0.5\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp9r7fbg7f/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Prediction is \"Setosa\" (77.9%)\n"
     ]
    }
   ],
   "source": [
    "# Actually creating predictions\n",
    "def input_fn2(features, batch_size=256):\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted:\")\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val =  input(feature + \": \")\n",
    "        if not val.isdigit():\n",
    "            valid = False\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn = lambda: input_fn2(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "    \n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100  * probability)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b2f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
