{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdfa3289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 21:31:03.034041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-03 21:31:03.034077: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cac48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = tf.keras.utils.get_file('shakespeare.txxt', 'http://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef3247ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# if you want to use your own file\n",
    "# from google.colab import files\n",
    "# path_to_file = list(files.upload().keys())[0]\n",
    "\n",
    "text= open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "print('Length of text: {} characters'.format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5327bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: First Citizen\n",
      "Encoding:  [18 47 56 57 58  1 15 47 58 47 64 43 52]\n"
     ]
    }
   ],
   "source": [
    "# encoding\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text):\n",
    "    return np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int = text_to_int(text)\n",
    "\n",
    "print(\"Text:\", text[:13])\n",
    "print(\"Encoding: \", text_to_int(text[:13]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf80a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "print(idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3ef796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_to_text(ints):\n",
    "    try:\n",
    "        ints = ints.numpy()\n",
    "    except:\n",
    "        pass\n",
    "    return ''.join(idx2char[ints])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e379861d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 21:31:20.403895: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-08-03 21:31:20.403952: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n",
      "2022-08-03 21:31:20.413989: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Creating Training Examples\n",
    "# feed input sequence, output is original sequence shifted 1 letter to the right\n",
    "# basically predicts the next char\n",
    "\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)\n",
    "\n",
    "# create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2cd6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7190e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8869406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab) # of unique chars\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "\n",
    "# buffer size to shuffle the datatset\n",
    "BUFFER_SIZE = 10000\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17efd9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 256)           16640     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 1024)          5246976   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,330,241\n",
      "Trainable params: 5,330,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                 batch_input_shape=[batch_size, None]), # none = don't know lenght of sequence\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73348de3",
   "metadata": {},
   "source": [
    "## Creating a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c6d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65) # (batch_size, sequence_length, vocab_size)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-03 21:31:23.065461: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26214400 exceeds 10% of free system memory.\n",
      "2022-08-03 21:31:23.076598: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 26214400 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1):\n",
    "    example_batch_predictions = model(input_example_batch) # ask our model for a prediction on our first batch of training data\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")  # print out the output shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed99984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[ 9.5528122e-03 -1.5443719e-03 -4.7377208e-03 ... -5.0634122e-04\n",
      "   -5.0597952e-04 -6.6094217e-03]\n",
      "  [ 8.6294012e-03  1.4757626e-03  9.6377230e-04 ... -5.4431311e-04\n",
      "    4.2970935e-03 -5.3331284e-03]\n",
      "  [ 1.1695606e-02  6.0755471e-03 -3.3139391e-03 ...  4.1671931e-03\n",
      "    1.8944028e-03 -7.1819536e-03]\n",
      "  ...\n",
      "  [ 5.6431200e-03 -3.7155938e-03  2.1505128e-03 ... -3.6936773e-03\n",
      "    3.7387027e-03 -4.3226578e-03]\n",
      "  [ 1.3665174e-02 -4.4317832e-03 -2.9737600e-03 ... -3.7974138e-03\n",
      "    2.0989524e-03 -1.0513639e-02]\n",
      "  [ 9.7278384e-03 -3.4630508e-03 -1.9981777e-03 ... -6.6221622e-03\n",
      "    3.1717923e-03 -1.2708948e-02]]\n",
      "\n",
      " [[ 3.7754264e-03  1.3086944e-03  5.8634910e-03 ...  5.7026162e-04\n",
      "    4.2824363e-03 -4.7717905e-03]\n",
      "  [ 3.5868571e-03 -2.3741687e-03  1.5797524e-03 ... -3.9814780e-03\n",
      "    3.5142768e-03 -3.0483003e-04]\n",
      "  [ 7.3570805e-03  4.2919698e-03 -3.0486714e-03 ...  2.0886546e-03\n",
      "    2.1278777e-03 -3.0744071e-03]\n",
      "  ...\n",
      "  [ 8.9818817e-03 -6.7843194e-03 -1.7906090e-02 ... -6.3822898e-03\n",
      "    6.4120628e-04 -8.9959364e-04]\n",
      "  [ 1.1639884e-02  1.1302584e-03 -1.8900540e-02 ... -6.0130702e-04\n",
      "    5.3039542e-04 -2.6494130e-03]\n",
      "  [ 8.3717518e-03  7.0927199e-03 -1.8057957e-02 ...  9.3619456e-04\n",
      "    1.8140061e-04 -3.3360417e-03]]\n",
      "\n",
      " [[-3.9965818e-03 -1.3962763e-03 -1.2347416e-04 ...  3.0394392e-03\n",
      "    7.6829281e-04 -4.4687493e-03]\n",
      "  [-1.3804007e-03 -6.1273733e-03  4.1130306e-03 ...  2.0148954e-04\n",
      "    8.1128092e-04 -4.8156241e-03]\n",
      "  [ 5.2409740e-03  7.1399729e-05  1.0177395e-03 ...  4.2812438e-03\n",
      "   -3.6630422e-04 -7.9495879e-03]\n",
      "  ...\n",
      "  [-1.0722841e-03  9.3306713e-03 -1.0344695e-02 ... -2.8597373e-03\n",
      "   -1.4654372e-02 -4.9664481e-03]\n",
      "  [-2.4172601e-03  6.5344730e-03 -6.7491513e-03 ... -2.6357546e-04\n",
      "   -6.0055857e-03 -3.7089223e-05]\n",
      "  [-4.0668803e-03  5.9620803e-03 -7.6760547e-03 ... -1.5726690e-03\n",
      "    2.4319114e-04 -9.8925550e-05]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 9.5528122e-03 -1.5443719e-03 -4.7377208e-03 ... -5.0634122e-04\n",
      "   -5.0597952e-04 -6.6094217e-03]\n",
      "  [ 4.6166098e-03 -8.2075568e-03 -1.8122774e-03 ... -1.3569888e-03\n",
      "   -1.7087653e-03 -3.3017558e-03]\n",
      "  [ 4.2264848e-03 -9.6720178e-03  1.9709871e-03 ... -1.9940743e-03\n",
      "   -7.2196673e-04 -3.6840485e-03]\n",
      "  ...\n",
      "  [ 1.2805653e-03  5.6825406e-03  6.8211639e-03 ...  7.0651928e-03\n",
      "   -5.3722635e-03  3.4382087e-03]\n",
      "  [ 1.0043448e-02  2.8181509e-03 -9.9024037e-04 ...  4.7304705e-03\n",
      "   -5.7252953e-03 -3.2845056e-03]\n",
      "  [ 5.0680381e-03  4.6024476e-03  1.3294751e-03 ...  8.0458634e-03\n",
      "   -9.3899649e-03 -1.3947859e-03]]\n",
      "\n",
      " [[-3.9965818e-03 -1.3962763e-03 -1.2347416e-04 ...  3.0394392e-03\n",
      "    7.6829281e-04 -4.4687493e-03]\n",
      "  [ 1.3162515e-03 -1.9191856e-03  8.3924318e-03 ... -8.7602274e-04\n",
      "   -9.1004721e-04 -1.2982823e-02]\n",
      "  [ 4.8963404e-03 -4.1945479e-03  8.0800764e-03 ... -3.4665763e-03\n",
      "    1.2787299e-03 -9.7624315e-03]\n",
      "  ...\n",
      "  [-5.2519920e-03  1.7380683e-03  2.6004170e-03 ... -5.2265725e-03\n",
      "   -3.3688080e-03 -1.5130150e-02]\n",
      "  [-6.1723311e-03  3.5189046e-03  5.6205709e-03 ...  1.0377286e-03\n",
      "   -7.5010015e-03 -1.0574848e-02]\n",
      "  [ 4.2667161e-03  7.0519000e-04 -1.3363475e-03 ...  7.3833193e-04\n",
      "   -6.7220712e-03 -1.5005826e-02]]\n",
      "\n",
      " [[ 9.5528122e-03 -1.5443719e-03 -4.7377208e-03 ... -5.0634122e-04\n",
      "   -5.0597952e-04 -6.6094217e-03]\n",
      "  [ 7.8141158e-03 -4.5361691e-03 -6.3579837e-03 ... -4.9502822e-03\n",
      "    3.1953253e-04 -2.2431116e-03]\n",
      "  [ 8.3734635e-03 -1.6834111e-03 -5.0780724e-04 ... -2.8612318e-03\n",
      "    4.8595835e-03 -6.4246370e-03]\n",
      "  ...\n",
      "  [-5.1195291e-04 -1.2055106e-02  4.5140777e-03 ... -3.7807303e-03\n",
      "   -6.0819497e-04 -1.3188500e-02]\n",
      "  [ 9.1640707e-03 -1.1440584e-02 -1.2366932e-03 ... -3.9009373e-03\n",
      "   -1.6009018e-03 -1.8457191e-02]\n",
      "  [ 1.0387683e-02 -4.3689385e-03 -4.5242999e-03 ... -5.6413342e-03\n",
      "   -2.4295573e-03 -2.2881158e-02]]], shape=(64, 100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(len(example_batch_predictions))\n",
    "print(example_batch_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4239832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[ 0.00955281 -0.00154437 -0.00473772 ... -0.00050634 -0.00050598\n",
      "  -0.00660942]\n",
      " [ 0.0086294   0.00147576  0.00096377 ... -0.00054431  0.00429709\n",
      "  -0.00533313]\n",
      " [ 0.01169561  0.00607555 -0.00331394 ...  0.00416719  0.0018944\n",
      "  -0.00718195]\n",
      " ...\n",
      " [ 0.00564312 -0.00371559  0.00215051 ... -0.00369368  0.0037387\n",
      "  -0.00432266]\n",
      " [ 0.01366517 -0.00443178 -0.00297376 ... -0.00379741  0.00209895\n",
      "  -0.01051364]\n",
      " [ 0.00972784 -0.00346305 -0.00199818 ... -0.00662216  0.00317179\n",
      "  -0.01270895]], shape=(100, 65), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# one prediction\n",
    "# 2d array of length 100\n",
    "\n",
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d7a1baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "tf.Tensor(\n",
      "[ 0.00955281 -0.00154437 -0.00473772 -0.00278807  0.00196686 -0.0009838\n",
      "  0.00448267 -0.00170477 -0.00292637 -0.00286418 -0.00339941  0.00230169\n",
      " -0.00616335 -0.00087049  0.00276717 -0.00083601  0.00197117  0.00177544\n",
      "  0.00516547 -0.00537197  0.00496557 -0.00050042 -0.00096579  0.00347758\n",
      " -0.00211366 -0.00114929  0.00601353 -0.00135903  0.01222187  0.00389455\n",
      " -0.0030307   0.0025818   0.00353166  0.00094268 -0.00245645 -0.00292408\n",
      " -0.00289008  0.00266008  0.00090725  0.00048019  0.00351178  0.00271758\n",
      "  0.00397447 -0.00143788 -0.00235832  0.00104913 -0.01012344 -0.00738153\n",
      "  0.00248223  0.00195208  0.00363751  0.00122833  0.00154249  0.00137983\n",
      "  0.00249369  0.00025042  0.00032394  0.00429677  0.00437514 -0.00581795\n",
      "  0.00250042  0.00246434 -0.00050634 -0.00050598 -0.00660942], shape=(65,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# predictoion at the first timestep\n",
    "# it is 65 values representing prob of each character occuring enxt\n",
    "\n",
    "time_pred = pred[0]\n",
    "print(len(time_pred))\n",
    "print(time_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8075b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" DZ? EHOn-bQNEjDlXH-ECbWkFZq\\nA$c;r DLV3&gtb $l\\nDz\\nISyGWPzju&ish\\nLme;&KtYWzte3'dM!kYRHwZ--.I'iQ-v&!P&\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to make own loss function\n",
    "# sample output distribution, will tell us the predicted characcter\n",
    "\n",
    "sampled_indices = tf.random.categorical(pred, num_samples=1)\n",
    "\n",
    "sampled_indices = np.reshape(sampled_indices, (1, -1))[0]\n",
    "preicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars = int_to_text(sampled_indices)\n",
    "\n",
    "predicted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5ce2800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5ce27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam',loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac71ce78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoints\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7c82647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 419s 2s/step - loss: 2.2653\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "history = model.fit(data, epochs=1, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99fccf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a689367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the text\n",
    "\n",
    "def generate_text(model, start_string):\n",
    "    # num of chars to gen\n",
    "    num_generate = 800\n",
    "    \n",
    "    # converting start string to numbers\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0) # turns a list into a nested list\n",
    "    \n",
    "    # empty string to store result\n",
    "    generated_text = []\n",
    "    \n",
    "    # low temps results in more predictable text\n",
    "    # higher results in more surprising text\n",
    "    temperature = 1.0\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        # remove batch dimension\n",
    "        predictions = tf.squeeze(predictions, 0) # takes a nested list, removes the exterior list\n",
    "        \n",
    "        # using a categorical disstribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        # we pass predicted char as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        generated_text.append(idx2char[predicted_id])\n",
    "        \n",
    "    return (start_string + ''.join(generated_text))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1322d357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type a starting string: romeo\n",
      "romeo\n",
      ";NaZPRck$hlF'gk$\n",
      "kj\n",
      "zfzdCvc,b&sUymvY-q.Ih3MCPL\n",
      "v:zR$GvkHKQ &N\n",
      "PyakjCNE:rv'B\n",
      "IZPhH$iV-V.rP.D?PQapD'3sdttIDy\n",
      "Oh&VWA.GtED:eCROP?m?3DoL:'!-XHVgOXOmYzOapASwoccv\n",
      "EAP!e W$r' ,XIv\n",
      ".'Q!A\n",
      "hpAKoi.'RjYca!LFQ-CLM.'DkJngvxyVLuQFcvbeA3Pkej.j!':OSev,'fgq3BUY!3:YG$Np'XDmhXa$TvmeTnFskk'd3'VJR;FVGq'!ip\n",
      "&KFLYIC?ygU.&S$Utcqp$BqjVyMN'DEq?O\n",
      "''ozxXuWx\n",
      "Rtr'Eby$NiqK-c\n",
      "Me-:!EJQ\n",
      "BwePWQJgM:ohE'epsUUS:g&UtpEYcT,Bm\n",
      "wrtqd&;,BdhwW\n",
      "TYiJNBdMkyku,HU:YnyLP&gC.godi!OYsXVjiT-;i?LudmK'KMudZX-a;GFIi3rN&FWlxThvG'HVm: qqiLKUL lA Gf\n",
      ",u,DbGCUpzc'meTTd,LyePtxdeN-k.XU,iCaI:F-CqBNJSxfGSBuGNR3XoBZJSsXEUikKL!vGvfiv$MWILNHB,jYF;XkXbFBQls?x';I;StG'PxzKzsZM;w3;tG?qzF?fDHhgl!o-;s$WiQheSFMrpYcWFDD'XQJ;eQP3zKYMrijy.ho!HDNEuIxa:uXN3T.3kpBOxftglMMuBAbYEWTvMVsF!qDULdDQaexJaHzb!dveej3BxncQ,$QUd3BN3rTzwuzIMi.MySwwf.E-wp;wrXpD'U.KBjzelnO$L.nBN\n",
      "IDfUO\n"
     ]
    }
   ],
   "source": [
    "inp = input (\"Type a starting string: \")\n",
    "print(generate_text(model, inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd95c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
