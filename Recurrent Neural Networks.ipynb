{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5678f7f6",
   "metadata": {},
   "source": [
    "# Usage:\n",
    "- usefull for sequential data such as text or characters\n",
    "- sentiment analysis\n",
    "- character generation\n",
    "- goal: write a play"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78d429",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "- every single word in datatset is the vocabulary\n",
    "- every word will be placed in a dictionary, with val being an integer that represents it\n",
    "- Whenever we see a word we'll throw its number into the bag\n",
    "- lose order, but keep track of the frequency\n",
    "- feed the bag into neural network\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "Consider this:\n",
    "- I thought the movie was going to be bad, but it was actually amazing\n",
    "- I thought the movie was going to be amazing, but it was actually bad\n",
    "\n",
    "This technique offers no distinction with these two sentences, as only frequency is considered; needs context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb6013",
   "metadata": {},
   "source": [
    "### Word embedding\n",
    "- translate each word into a vector\n",
    "- their angle determined by semantics: similar words have similar angles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e703e8ac",
   "metadata": {},
   "source": [
    "### Recurrent NN\n",
    "- conatins a loop: process  one word at a time while maintaining an internal memory of what it has already seen\n",
    "- treating input as a sequence\n",
    "\n",
    "#### Special Layers:\n",
    "- Simple RNN layer\n",
    "    - think of converyor belt\n",
    "    - looks at current / prev word, creates a model based on that\n",
    "- LSTM layer\n",
    "    - accesses output from any state from any previous cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ec07ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 21:11:42.779318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-01 21:11:42.779354: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17464789/17464789 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Movie reviews\n",
    "# encoding based on how common a word is in a dataset\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bf0d3bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "# add padding, as everything has to be the same length\n",
    "train_data = pad_sequences(train_data, MAXLEN)\n",
    "test_data = pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "419a8484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 21:18:19.091666: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-08-01 21:18:19.093860: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n",
      "2022-08-01 21:18:19.109172: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# creating the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ad0976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          2834688   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                8320      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,843,041\n",
      "Trainable params: 2,843,041\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e04073f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 33s 49ms/step - loss: 0.4098 - acc: 0.8120 - val_loss: 0.3155 - val_acc: 0.8708\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 30s 49ms/step - loss: 0.2385 - acc: 0.9100 - val_loss: 0.3460 - val_acc: 0.8468\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 0.1811 - acc: 0.9340 - val_loss: 0.2756 - val_acc: 0.8958\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 0.1513 - acc: 0.9470 - val_loss: 0.3237 - val_acc: 0.8702\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.1298 - acc: 0.9551 - val_loss: 0.3160 - val_acc: 0.8746\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.1138 - acc: 0.9608 - val_loss: 0.2850 - val_acc: 0.8882\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 32s 51ms/step - loss: 0.0979 - acc: 0.9668 - val_loss: 0.3250 - val_acc: 0.8888\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 31s 49ms/step - loss: 0.0866 - acc: 0.9724 - val_loss: 0.3435 - val_acc: 0.8896\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.0775 - acc: 0.9754 - val_loss: 0.3734 - val_acc: 0.8856\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 31s 50ms/step - loss: 0.0681 - acc: 0.9782 - val_loss: 0.3472 - val_acc: 0.8864\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "949d6b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 21:31:36.670905: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 25000000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 12s 15ms/step - loss: 0.4134 - acc: 0.8602\n",
      "[0.41340261697769165, 0.8602399826049805]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ed772b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0   12   17   13   40  477  446    1 4622]\n"
     ]
    }
   ],
   "source": [
    "# making predictions\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# encoding function\n",
    "def encode_text(text):\n",
    "    tokens = tf.keras.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "text = \"that movie was just amazing, oh the misery\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db071f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was just amazing oh the misery \n"
     ]
    }
   ],
   "source": [
    "# decode function\n",
    "\n",
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != 0:\n",
    "            text += reverse_word_index[num] + \" \"\n",
    "    return text\n",
    "\n",
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8074169b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "[0.9113181]\n"
     ]
    }
   ],
   "source": [
    "# making predictions\n",
    "\n",
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1 , 250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred)\n",
    "    print(result[0])\n",
    "\n",
    "    \n",
    "text = \"this movie was great really loved it and would watch it again because it was amazingly great engaging plot\"\n",
    "predict(text)\n",
    "\n",
    "# lower number = more negative\n",
    "# higher number = more positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e8d33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
